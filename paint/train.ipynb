{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RUN = 'O'\n",
    "SAMPLE_SIZE = (3+2048*5)*2\n",
    "MODELS_DIR = '/d3/caches/kaggle-painters-v3/models/' + RUN\n",
    "TFB_DIR = '/tmp-persistent/painters3/' + RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(MODELS_DIR): os.makedirs(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_N_SAMPLES_PER_EPOCH 499840\n",
      "TRAIN_N_EPOCHS 11111\n"
     ]
    }
   ],
   "source": [
    "# how many same-artist \n",
    "SAME_ARTIST_PROB = 0.55\n",
    "\n",
    "VAL_N_SAMPLES = 125000\n",
    "VAL_SAMPLES_FILE = 'out/X_val.mem'\n",
    "VAL_YS_FILE = 'out/y_val.mem'\n",
    "\n",
    "HSS_CACHE_FILE = 'out/halfsamples.npy'\n",
    "\n",
    "TRAIN_N_PER_BATCH = 320\n",
    "TRAIN_N_SAMPLES_PER_EPOCH = 500000\n",
    "TRAIN_N_SAMPLES_PER_EPOCH -= TRAIN_N_SAMPLES_PER_EPOCH % TRAIN_N_PER_BATCH\n",
    "\n",
    "TRAIN_N_EPOCHS = 11111\n",
    "\n",
    "print ('TRAIN_N_SAMPLES_PER_EPOCH', TRAIN_N_SAMPLES_PER_EPOCH)\n",
    "print ('TRAIN_N_EPOCHS', TRAIN_N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# fids in training set: 79433\n"
     ]
    }
   ],
   "source": [
    "\n",
    "info_df = pd.read_csv('train_info.csv')\n",
    "info_df['fid'] = [int(re.findall(r'(\\d+).jpg$', x)[0]) for x in info_df['filename']]\n",
    "info_df = info_df.set_index('fid', drop=True)\n",
    "\n",
    "\n",
    "avail_fids = np.array(info_df.index.values, dtype=np.int32)\n",
    "print (\"# fids in training set: %d\"%(len(avail_fids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1584/1584 [00:03<00:00, 420.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# same-artist pairs: 5773652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate pairs\n",
    "artists = np.unique(info_df.artist.values)\n",
    "same_artist_fids = []\n",
    "\n",
    "for a in tqdm(artists):\n",
    "    info_artist_df = info_df[info_df['artist'] == a]\n",
    "    \n",
    "    np.random.shuffle(info_artist_df.index.values)\n",
    "    \n",
    "    for c in combinations(info_artist_df.index.values, 2):\n",
    "        same_artist_fids.append(c)\n",
    "\n",
    "same_artist_fids = np.array(same_artist_fids, dtype=np.int32)\n",
    "\n",
    "print (\"# same-artist pairs: %d\"%(len(same_artist_fids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read halfsamples cache\n",
    "hss_cache = np.load(HSS_CACHE_FILE).item()\n",
    "\n",
    "# create sample from bottlecks, dpi and ARs of a pair\n",
    "def create_pair_sample(fid1, fid2, hss_cache=hss_cache):\n",
    "    \n",
    "    hs1 = hss_cache[fid1]\n",
    "    hs2 = hss_cache[fid2]\n",
    "    \n",
    "    return np.hstack((hs1, hs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same pair generation\n",
    "\n",
    "same_artist_ix = -1\n",
    "\n",
    "def get_same_pair(flip_on_even_pass=False):\n",
    "    global same_artist_ix\n",
    "    same_artist_ix += 1\n",
    "    \n",
    "    l = len(same_artist_fids)\n",
    "    \n",
    "    ix = same_artist_ix % l\n",
    "    \n",
    "        # shuffle fids on each iteration start\n",
    "    if 0 == ix:\n",
    "        print ('shuffling same-artist pairs...')\n",
    "        np.random.shuffle(same_artist_fids)\n",
    "    \n",
    "    pair = same_artist_fids[ix]\n",
    "\n",
    "    if flip_on_even_pass and (float(same_artist_ix) / l % 2 >= 1):\n",
    "        return np.flipud(pair) # on even passes flip pairs\n",
    "    else:\n",
    "        return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diff pair generation\n",
    "\n",
    "diff_pairs_used = {}\n",
    "def is_diff_pair_used(p, add=True):\n",
    "    global diff_pairs_used\n",
    "    \n",
    "    if not diff_pairs_used.has_key(p[0]):\n",
    "        diff_pairs_used[p[0]] = {}\n",
    "\n",
    "    if not diff_pairs_used.has_key(p[1]):\n",
    "        diff_pairs_used[p[1]] = {}\n",
    "\n",
    "    if diff_pairs_used[p[0]].has_key(p[1]) or \\\n",
    "        diff_pairs_used[p[1]].has_key(p[0]):\n",
    "        return True\n",
    "\n",
    "    if add:\n",
    "        diff_pairs_used[p[0]][p[1]] = True\n",
    "        diff_pairs_used[p[1]][p[0]] = True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_different_pair():\n",
    "    while True:\n",
    "        pair = np.random.choice(avail_fids, 2, replace=True)\n",
    "        if pair[0] == pair[1]: continue\n",
    "        if info_df.ix[pair[0]].artist == info_df.ix[pair[1]].artist: continue\n",
    "        if is_diff_pair_used(pair, add=True): continue\n",
    "        return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_datafile(X_f=None, y_f=None, n_samples=10, memfiles=False):\n",
    "    \n",
    "    if memfiles:\n",
    "        # memory-mapped records store\n",
    "        print ('Creating ', X_f, y_f, '...'; time.sleep(0.5))\n",
    "        Xs = np.memmap(X_f, dtype=np.float32, mode='w+', shape=(n_samples,SAMPLE_SIZE))\n",
    "        ys = np.memmap(y_f, dtype=np.float32, mode='w+', shape=(n_samples, 2))\n",
    "    else:\n",
    "        Xs = np.zeros([n_samples, SAMPLE_SIZE], dtype=np.float32)\n",
    "        ys = np.zeros([n_samples, 2], dtype=np.float32)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        \n",
    "        if np.random.rand() < SAME_ARTIST_PROB:\n",
    "            y = [1., 0.]\n",
    "            pair = get_same_pair()    \n",
    "        else:\n",
    "            y = [0., 1.]\n",
    "            pair = get_different_pair()\n",
    "\n",
    "        Xs[i] = create_pair_sample(pair[0], pair[1])\n",
    "        ys[i] = y\n",
    "    \n",
    "    if memfiles:\n",
    "        ys.flush()\n",
    "        Xs.flush()\n",
    "        gc.collect()\n",
    "    \n",
    "    return Xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling same-artist pairs...\n"
     ]
    }
   ],
   "source": [
    "# gen validation file\n",
    "X_val, y_val = gen_datafile(\n",
    "    X_f=VAL_SAMPLES_FILE,\n",
    "    y_f=VAL_YS_FILE,\n",
    "    n_samples=VAL_N_SAMPLES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same-artist combinations used in validation set: 68568\n",
      "Same-artist combinations left: 5705084\n"
     ]
    }
   ],
   "source": [
    "# remove portion of same-artists pair used for validation from training data\n",
    "print ('Same-artist combinations used in validation set:', 1 + same_artist_ix)\n",
    "\n",
    "same_artist_fids = same_artist_fids[same_artist_ix+1:]\n",
    "same_artist_ix = -1\n",
    "\n",
    "print ('Same-artist combinations left:', len(same_artist_fids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data generator\n",
    "def generate_sample():\n",
    "    while 1:\n",
    "        yield gen_datafile(n_samples=TRAIN_N_PER_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- *Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_auc():\n",
    "    s = 0\n",
    "    n = X_val.shape[0]\n",
    "    y_p = model.predict(X_val[s:s+n], verbose=False)\n",
    "    y_p = np.nan_to_num(y_p)\n",
    "    return metrics.roc_auc_score(y_val[s:s+n].T[0], y_p.T[0])\n",
    "\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def _validate(self):\n",
    "        s = score_auc()\n",
    "        scores.append(s)\n",
    "        print (\"\\n\\n AUC = %.5f\\n\"%s; time.sleep(.5))\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv1D\n",
    "from keras.regularizers import l2, activity_l2\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(4096, input_dim=SAMPLE_SIZE, activation='relu', init='glorot_uniform'),\n",
    "    Dropout(0.55),\n",
    "    Dense(4096, activation='relu', init='glorot_uniform'),\n",
    "    Dropout(0.25),\n",
    "    Dense(2048, activation='relu', init='glorot_uniform'),\n",
    "    Dropout(0.25), \n",
    "    Dense(1024, activation='relu', init='glorot_uniform'),\n",
    "    Dropout(0.25),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " AUC = 0.51403\n",
      "\n",
      "Epoch 1/11111\n",
      "shuffling same-artist pairs...\n",
      "345600/499840 [===================>..........] - ETA: 32s - loss: 0.6803 - acc: 0.5669"
     ]
    }
   ],
   "source": [
    "# train\n",
    "hist = model.fit_generator(\n",
    "        generate_sample(),\n",
    "        samples_per_epoch=TRAIN_N_SAMPLES_PER_EPOCH,\n",
    "        nb_epoch=TRAIN_N_EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=True,\n",
    "        max_q_size=100,\n",
    "        nb_worker=1,\n",
    "        pickle_safe=False,\n",
    "        callbacks = [\n",
    "            MyCallback(),\n",
    "            keras.callbacks.TensorBoard(log_dir=TFB_DIR, histogram_freq=0),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                MODELS_DIR + \\\n",
    "                '/e{epoch:02d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5', \n",
    "                monitor='val_acc', verbose=0, save_best_only=False, \n",
    "                save_weights_only=False, mode='auto'\n",
    "            ),\n",
    "        ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
